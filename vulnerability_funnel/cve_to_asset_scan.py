#!python

"""
This script pulls all vulnerabilities with given criteria then all findings

https://pan.dev/prisma-cloud/api/cspm/vulnerabilities-search-api/
/uve/api/v1/vulnerabilities/search

# Outdated API Docs. We will request an update.
https://pan.dev/prisma-cloud/api/cspm/list-vulnerable-assets-cve-v-2/
/uve/api/v1/vuln-assets

Rate Limit Info
https://pan.dev/prisma-cloud/api/cspm/rate-limits/

https://docs.prismacloud.io/en/enterprise-edition/rn/known-issues/known-fixed-issues
Fixed in 31.02.133
Fixed an issue where REST API requests triggered rate limiting after 23 requests
in a 30 second interval. With this fix, the rate limit for Prisma Cloud Compute
REST APIs is increased to 30 requests in 30 seconds.
(Last updated: April 29, 2025 as of May 2, 2025)

"""

# Prerequisite packages to run this script.
# pip install pprintpp requests prismacloud-api

import csv
from datetime import datetime
import json
import os
import shutil
import sys

# https://github.com/PaloAltoNetworks/pc-python-integration
from pcpi import session_loader

current_datetime = datetime.now()
formatted_datetime = current_datetime.strftime("%Y-%m-%d_%H-%M-%S")

ENABLE_CACHING = False

def http_logging():
    #############################################################################################
    import logging

    # These two lines enable debugging at httplib level (requests->urllib3->http.client)
    # You will see the REQUEST, including HEADERS and DATA, and RESPONSE with HEADERS but without DATA.
    # The only thing missing will be the response.body which is not logged.
    try:
        import http.client as http_client
    except ImportError:
        # Python 2
        import httplib as http_client
    http_client.HTTPConnection.debuglevel = 1

    # You must initialize logging, otherwise you'll not see debug output.
    logging.basicConfig()
    logging.getLogger().setLevel(logging.DEBUG)
    requests_log = logging.getLogger("requests.packages.urllib3")
    requests_log.setLevel(logging.DEBUG)
    requests_log.propagate = True
    ####################################################################################
# http_logging()

if "HOME" in os.environ.keys():
    user_home = os.environ.get("HOME")
    file_path = f"{user_home}/.prismacloud/credentials.json"
elif "USERPROFILE" in os.environ.keys():
    user_home = os.environ.get("USERPROFILE")
    file_path = f"{user_home}/.prismacloud/credentials.json"
else:
    file_path = "" 
    # Default behavior should be to look 
    # ~/.prismacloud/credentials.json but it would be common to want to manually set this credential file location

# The goal is for the file path to point to this location
# file_path = f"~/.prismacloud/credentials.json"
# https://github.com/PaloAltoNetworks/pc-python-integration
session_managers = session_loader.load_config(
    file_path=file_path
)  
# Example credentials.json
# [
#     {
#         "name": "My Tenant",
#         "url": "https://api.ca.prismacloud.io",
#         "identity": "**********",
#         "secret": "*********",
#         "verify": "true",
#         "proxies": null,
#         "project_flag": "false"
#     }
# ]
# (identifier_name=PRISMA_ACCESS_KEY, secret_name=PRISMA_SECRET_KEY, api_url_name=DOMAIN) # returns single session manager
session_man = session_managers[0]
cspm_session = session_man.create_cspm_session()

# url = f"{settings["url"]}/uve/api/v1/vulnerabilities/search"
# https://api.prismacloud.io/uve/api/v1/vulnerabilities/search


# Get all impacted assets for a CVE
def vuln_asset_req(cve, asset_type, risk):
    print(f"Printing {cve} of type {asset_type}")
    vurl = "/uve/api/v1/vuln-assets"
    # https://pan.dev/prisma-cloud/api/cspm/list-vulnerable-assets-cve-v-2/
    page_size = 101
    page_offset = 0
    # asset_type = "package"
    severity = '["high","critical"]'
    try:
        # while True:
        payloadv = (
            '{"cve_id":"'
            + cve
            + '","page_offset":"'
            + str(page_offset)
            + '","page_size":'
            + str(page_size)
            + ',"asset_type":"'
            + asset_type
            + '","filter_suppressed":true,"severity":'
            + severity
            + "}"
        )
        vulns = cspm_session.request("POST", vurl, data=payloadv)
        vulns.raise_for_status()
        response_json = json.loads(vulns.text)
        vuln_assets = response_json["value"]["assets"]
        vuln_count = len(vuln_assets)
        print(f"Found the next {vuln_count}: {response_json['value']['cve_id']}")
        if vuln_count != 0:
            # print(f"{response_json}")
            with open(f"logs/{risk}/{asset_type}/{cve}.json", "+w") as file:
                print(f"Printing file for {asset_type}/{cve}")
                json.dump(response_json, file, indent=4)

        page_offset += page_size
        # if vuln_count < page_size:
        #   time.sleep(1)
        # break
    except Exception as e:
        print(e)
        exception_line_writer(e)


# Loop over risk factors for CVE impacted assets
def req_all_types(cve, risk):
    print(f"Querying {cve}")
    risk_factor_list = [
        "critical severity",
        "high severity",
        "package in use",
        "exploitable",
        "internet exposed",
        "patchable",
        "running as privileged container",
    ]
    asset_type_list = [
        "package",
        "iac",
        "deployedImage",
        "serverlessFunction",
        "vmImage",
        "registryImage",
        "host",
    ]
    for asset_type in asset_type_list:
        folder_path = f"logs/{risk}/{asset_type}"
        if not os.path.exists(folder_path):
            print(f"Creating dir {folder_path}")
            os.makedirs(folder_path)
        cve_path = f"{folder_path}/{cve}.json"
        if not ENABLE_CACHING and not os.path.exists(cve_path):
            print(f"Finding package vulns for {cve}")
            vuln_asset_req(cve=cve, asset_type=asset_type, risk=risk)
        else:
            print(f"Using local cache for {cve_path}")
    print(f"Finished querying {cve}")


def loop_over_investigate_cve_list(payload, risk):
    running_count = 0
    # This is to collect the list of CVEs. For accurate results this needs to be similar to the Impacted Asset parameters.
    # payload = json.dumps(
    #     {
    #         "query": "vulnerability where asset.type IN ('Package', 'Iac', 'Container Registry Image', 'Vm Image', 'Deployed Image', 'Serverless Function', 'Host') AND severity IN ('high', 'critical')"
    #     }
    # )
    url = "/uve/api/v1/vulnerabilities/search"
    # url = f"{settings["url"]}/uve/api/v1/vulnerabilities/search"
    # https://api.prismacloud.io/uve/api/v1/vulnerabilities/search

    l = url
    page = 0
    try:
        # vuln_limiter = 0
        # for i in range(100):
        #   if(vuln_limiter > 2): # This loop makes tons of requests and we will eventually always use with more filters as a proper limit
        #     break
        #   vuln_limiter += 1
        while True:
            cve_file = f"logs/{risk}.{str(page)}.json"
            jr = ""
            if not os.path.exists(cve_file):
                response = cspm_session.request("POST", l, data=payload)
                response.raise_for_status()
                jr = json.loads(response.text)
                with open(cve_file, "w") as file:
                    file.write(json.dumps(jr))
            else:
                print(f"Using local cache for {risk}")
                with open(cve_file, "r") as file:
                    jr = json.loads(file.read())
            itemLength = len(jr["data"]["items"])
            running_count += itemLength
            print(f"Items: {itemLength} Page {page}: Parsed: {running_count}")
            page += 1
            if jr["data"]["nextPageToken"] is None:
                print(f"Finished paging through vulnerabilities for {risk}")
                break
            nextPageToken = jr["data"]["nextPageToken"]
            l = url + "?page_token=" + nextPageToken
    except Exception as e:
        print("exception with loop_over_investigate_cve_list")
        print(e)
        exception_line_writer(e)


# Read each CVE file and get their impacted assets
def get_all_files(directory, root_dir=dir):
    """
    Returns a list of all files in the given directory.
    """
    file_list = []
    for root, _, files in os.walk(directory):
        for file in files:
            file_path = os.path.join(root, file)
            if file_path.endswith(".json"):
                file_list.append(file_path)
    return file_list


# loop_over_investigate_cve_list()
# This is the library that will manage the sessions when the token quits working
# https://github.com/PaloAltoNetworks/pc-python-integration
def write_impacted_assets_to_csvs(risk):
    risk_log_path = f"logs/{risk}"
    if not os.path.exists(risk_log_path):
        print(f"Creating dir {risk_log_path}")
        os.makedirs(risk_log_path)
    # asset_type_list = [
    #     "package",
    #     "iac",
    #     "deployedImage",
    #     "serverlessFunction",
    #     "vmImage",
    #     "registryImage",
    #     "host",
    # ]
    grand_total_assets_impacted = 0

    ################################ DEPLOYED IMAGE
    filename = f"logs/{risk}/deployed_image_vulns_{formatted_datetime}.csv"
    deployed_image_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    deploy_image_files = get_all_files(f"logs/{risk}/deployedImage")
    print(f"Creating CSV for {len(deploy_image_files)} deployed image files")
    with open(filename, "a", newline="") as csv_file:
        print(f"Writing {filename}")
        writer = csv.DictWriter(csv_file, fieldnames=deployed_image_headers.keys())
        writer.writeheader()
        for file in deploy_image_files:
            with open(file, "r") as image_contents:
                json_contents = json.load(image_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        deployed_image_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(deployed_image_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {deployed_image_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} Deployed Images assets from {len(deploy_image_files)} files")
    ################################ PACKAGE
    filename = f"logs/{risk}/package_vulns_{formatted_datetime}.csv"
    package_headers = {
        "CVE": "",
        "Asset Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Repository": "",
        "File Name": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    package_files = get_all_files(f"logs/{risk}/package")
    print(f"Creating CSV for {len(package_files)} package files")
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=package_headers.keys())
        writer.writeheader()
        for file in package_files:
            print(f"Parsing {file}")
            with open(file, "r") as package_contents:
                json_contents = json.load(package_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        package_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Asset Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Repository": str(asset["repository"]),
                            "File Name": str(asset["filePath"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(package_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {package_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} Package assets from {len(package_files)} files")
    ################################ IAC
    filename = f"logs/{risk}/iac_vulns_{formatted_datetime}.csv"
    iac_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Repository": "",
        "File Name": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": ""
    }
    asset_count = 0
    iac_files = get_all_files(f"logs/{risk}/iac")
    print(f"Creating CSV for {len(iac_files)} iac files")
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=iac_headers.keys())
        writer.writeheader()
        for file in iac_files:
            print(f"Parsing {file}")
            with open(file, "r") as iac_contents:
                json_contents = json.load(iac_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        iac_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Repository": str(asset["repository"]),
                            "File Name": str(asset["filePath"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(iac_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {iac_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} IAC assets from {len(iac_files)} files")
    ################################### HOSTS
    filename = f"logs/{risk}/host_vulns_{formatted_datetime}.csv"
    host_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    host_files = get_all_files(f"logs/{risk}/host")
    print(f"Creating CSV for {len(host_files)} host files")
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=host_headers.keys())
        writer.writeheader()
        for file in host_files:
            print(f"Parsing {file}")
            with open(file, "r") as file_contents:
                json_contents = json.load(file_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        host_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(host_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {host_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} Host assets from {len(host_files)} files")
    ################################### Serverless Function
    filename = f"logs/{risk}/serverless_function_vulns_{formatted_datetime}.csv"
    serverless_function_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    serverless_function_files = get_all_files(f"logs/{risk}/serverlessFunction")
    print(f"Creating CSV for {len(serverless_function_files)} serverless files")    
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=serverless_function_headers.keys())
        writer.writeheader()
        for file in serverless_function_files:
            print(f"Parsing {file}")
            with open(file, "r") as file_contents:
                json_contents = json.load(file_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        serverless_function_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(serverless_function_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {serverless_function_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} Serverless Function assets from {len(serverless_function_files)} files")
    ################################### VM Image
    filename = f"logs/{risk}/vm_image_vulns_{formatted_datetime}.csv"
    vm_image_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    vm_image_files = get_all_files(f"logs/{risk}/vmImage")
    print(f"Creating CSV for {len(vm_image_files)} vm image files")    
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=vm_image_headers.keys())
        writer.writeheader()
        for file in vm_image_files:
            print(f"Parsing {file}")
            with open(file, "r") as file_contents:
                json_contents = json.load(file_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        vm_image_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(vm_image_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {vm_image_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} VM Image assets from {len(vm_image_files)} files")
    ################################### Registry Image
    filename = f"logs/{risk}/registry_image_vulns_{formatted_datetime}.csv"
    registry_image_headers = {
        "CVE": "",
        "Resource Name": "",
        "Package Name": "",
        "Package Version": "",
        "Fix Version": "",
        "Severity": "",
        "Discovered Time": "",
        "Age": "",
        "Action Results": "",
        "Actions": "",
    }
    asset_count = 0
    registry_image_files = get_all_files(f"logs/{risk}/registryImage")
    print(f"Creating CSV for {len(registry_image_files)} registry image files")    
    with open(filename, "a", newline="") as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=registry_image_headers.keys())
        writer.writeheader()
        for file in registry_image_files:
            print(f"Parsing {file}")
            with open(file, "r") as file_contents:
                json_contents = json.load(file_contents)
                asset_list = json_contents["value"]["assets"]
                asset_count += len(asset_list)
                grand_total_assets_impacted += len(asset_list)
                for asset in asset_list:
                    try:
                        registry_image_headers = {
                            "CVE": json_contents["value"]["cve_id"],
                            "Resource Name": str(asset["resourceName"]),
                            "Package Name": str(asset["packageName"]),
                            "Package Version": str(asset["packageVersion"]),
                            "Fix Version": str(asset["fixVersion"]),
                            "Severity": str(asset["severity"]),
                            "Discovered Time": get_time(asset["discoveredTime"]),
                            "Age": str(asset["age"] or ""),
                            "Action Results": f"{str(asset['remediationAvailable'][0]['action'] or '')} {str(asset['remediationAvailable'][0]['status'] or '')}",
                            "Actions": str(asset["remediationAvailable"][0]["message"] or ''),
                        }
                        writer.writerow(registry_image_headers)
                    except Exception as e:
                        print(f"error {file} {asset} {registry_image_headers}")
                        exception_line_writer(e)
        print(f"{asset_count} Registry Images assets from {len(registry_image_files)} files")
    all_files = get_all_files("logs/")
    file_set = set()
    for file in all_files:
        file_set.add(os.path.basename(file))
    print(f"{risk} - {grand_total_assets_impacted} assets from {len(all_files)} files and {len(file_set)} unique cves")
# write_impacted_assets_to_csvs()

def get_time(discovered_time):
    try:
        parsed_time = str(datetime.fromtimestamp(discovered_time))
    except Exception as e:
        print(f"WARN: Timestamp parsing error {e} for {discovered_time}")
        exception_line_writer(e)
        parsed_time = discovered_time
    return parsed_time

def exception_line_writer(exception):
    exc_type, exc_obj, exc_tb = sys.exc_info()
    fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
    print(exception, exc_type, fname, exc_tb.tb_lineno)

def get_impacted_assets_by_file(risk):
    # Loop over local files of CVE data allowing for caching and restart
    directory_path = "logs"  # Replace with the actual path
    all_files = []
    for dir_path, dir_list, json_file_list in os.walk(directory_path):
        for json_file in json_file_list:
            all_files.append(os.path.join(dir_path, json_file))
        break
    for file in all_files:
        print(f"for file: {file}")
        if not os.path.isdir(file) and risk in file and file.endswith(".json"):
            print(f"has risk type {risk}")
            with open(file, mode="r") as file_lines:
                contents = json.load(file_lines)
                for res in contents["data"]["items"]:
                    req_all_types(res["cveId"], risk=risk)

if not os.path.exists("logs"):
    os.makedirs("logs")

# Get all CVEs
try:
    query = "vulnerability where asset.type IN ('Package', 'Iac', 'Container Registry Image', 'Vm Image', 'Deployed Image', 'Serverless Function', 'Host') AND severity IN ('high', 'critical') AND risk.factors CONTAINS ALL ('exploitable', 'patchable', 'internet exposed', 'package in use')"
    in_use = json.dumps({"query": query})
    loop_over_investigate_cve_list(payload=in_use, risk="in_use")
    get_impacted_assets_by_file("in_use")
    write_impacted_assets_to_csvs("in_use")

    query = "vulnerability where asset.type IN ( 'Container Registry Image', 'Package', 'Vm Image', 'Deployed Image', 'Host', 'Iac', 'Serverless Function' ) AND risk.factors CONTAINS ALL ( 'Exploitable', 'Internet Exposed', 'Patchable' ) AND severity IN ( 'High', 'Critical' )"
    internet_exposed = json.dumps({"query": query})
    loop_over_investigate_cve_list(payload=internet_exposed, risk="internet_exposed")
    get_impacted_assets_by_file("internet_exposed")
    write_impacted_assets_to_csvs("internet_exposed")

    query = "vulnerability where asset.type IN ('Package', 'Iac', 'Container Registry Image', 'Vm Image', 'Deployed Image', 'Serverless Function', 'Host') AND severity IN ('high', 'critical') AND risk.factors CONTAINS ALL ('exploitable', 'patchable')"
    patchable = json.dumps({"query": query})
    loop_over_investigate_cve_list(payload=patchable, risk="patchable")
    get_impacted_assets_by_file("patchable")
    write_impacted_assets_to_csvs("patchable")

    # quit() # The number of cve and assets get very large and take a while to complete

    query = "vulnerability where asset.type IN ('Package', 'Iac', 'Container Registry Image', 'Vm Image', 'Deployed Image', 'Serverless Function', 'Host') AND severity IN ('high', 'critical') AND risk.factors IN ('exploitable')"
    exploitable = json.dumps({"query": query})
    loop_over_investigate_cve_list(payload=exploitable, risk="exploitable")
    get_impacted_assets_by_file("exploitable")
    write_impacted_assets_to_csvs("exploitable")

    query = "vulnerability where asset.type IN ('Package', 'Iac', 'Container Registry Image', 'Vm Image', 'Deployed Image', 'Serverless Function', 'Host') AND severity IN ('high', 'critical')"
    critical_and_high = json.dumps({"query": query})
    loop_over_investigate_cve_list(payload=critical_and_high, risk="critical_and_high")
    get_impacted_assets_by_file("critical_and_high")
    write_impacted_assets_to_csvs("critical_and_high")

    print("finished loop_over_investigate_cve_list")
except Exception as e:
    print(e)
    exception_line_writer(e)
    
# Zip up all files 
shutil.make_archive(f"cve_to_impacted_assets_{formatted_datetime}", 'zip', "logs/")

# Remaining Tasks
# [X] Asset type remaining
# [X] Risk factors
# [X] Session management library
# [X] Confirm page size doesn't limit results
# [X] Remove the break that limits to the first CVE file get_impacted_assets_by_file()

# Optimize and improve
# [ ] Use a database to hold the data
# [ ] Consider using the Pickle library
